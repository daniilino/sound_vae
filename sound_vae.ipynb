{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import utils, datasets\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils.audio_utils import RealTimeAudioStream\n",
    "from utils.vaes import *    \n",
    "from utils.data_utils import calculate_mean_std, split_train_val_test\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import math\n",
    "\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream your audio output and check what it visualizes\n",
    "\n",
    "# короче блять работает хуйня єта ебаная (PyAudio) только с микрофонами по-нормальному\n",
    "# а чтоб стримить аутпут системьі, то конечно лучше юзать пєкєдж soundcard\n",
    "# но там немного другой принцип работьі и єто охуеть можно\n",
    "# так что по ходу надо попробовать єтое: https://github.com/intxcc/pyaudio_portaudio/tree/master\n",
    "# audio_stream = RealTimeAudioStream()\n",
    "# audio_stream.stream(rms=True, zcr=True, fft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rotation_matrix(dim):\n",
    "    # Generate a random orthogonal matrix\n",
    "    x = torch.randn(dim, dim).requires_grad_(False)\n",
    "    q, _ = torch.linalg.qr(x)\n",
    "    \n",
    "    # Apply the SVD decomposition to obtain the rotation matrix\n",
    "    u, _, v = torch.linalg.svd(q)\n",
    "    rotation_matrix = u @ v.mT\n",
    "    \n",
    "    return rotation_matrix\n",
    "\n",
    "def interpolate_transforms(matrix1, matrix2, steps):\n",
    "    # Interpolate between two rotation matrices\n",
    "    transforms = []\n",
    "    for t in range(steps + 1):\n",
    "        weight = t / steps\n",
    "        interpolated_matrix = torch.lerp(matrix1, matrix2, weight).requires_grad_(False)\n",
    "        transforms.append(interpolated_matrix)\n",
    "    return transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing batch       50 / 50\n",
      "tensor([0.9359, 0.9359, 0.9359]) tensor([0.2315, 0.2315, 0.2315])\n"
     ]
    }
   ],
   "source": [
    "# custom dataset\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "WIDTH = 256\n",
    "HEIGHT = 128\n",
    "\n",
    "dataset_dir = r\"data/prepared\"\n",
    "\n",
    "# calculate dataset mean and std\n",
    "raw_transforms = T.Compose([\n",
    "    T.Resize((HEIGHT, WIDTH)), \n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "raw_data = datasets.ImageFolder(root = dataset_dir, transform = raw_transforms)\n",
    "\n",
    "DATA_MEAN, DATA_STD = calculate_mean_std(raw_data)\n",
    "# DATA_MEAN = [0.9386, 0.9386, 0.9386]\n",
    "# DATA_STD  = [0.1825, 0.1825, 0.1825]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 128, 256])\n",
      "tensor(-4.0421)\n",
      "tensor(0.2770)\n"
     ]
    }
   ],
   "source": [
    "data_transforms = T.Compose([\n",
    "    T.Resize((HEIGHT, WIDTH)), \n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=DATA_MEAN,std=DATA_STD),\n",
    "    T.Grayscale(),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root = dataset_dir, transform = data_transforms)\n",
    "\n",
    "# split into Train, Val and Test\n",
    "data = split_train_val_test(dataset, val=0.0, test=0.1, batch_size=batch_size)\n",
    "\n",
    "examples = enumerate(data['train'])\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(example_data.shape)\n",
    "print(example_data.min())\n",
    "print(example_data.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_test(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        latents = []\n",
    "        labels = []\n",
    "        for x, y in test_loader:\n",
    "            mu, log_var = model.encoder(x.cuda())\n",
    "            z = model.sampling(mu, log_var).cpu().numpy()\n",
    "\n",
    "            latents.append(z)\n",
    "            labels.append(y)\n",
    "\n",
    "    latents = np.concatenate(latents, 0)\n",
    "    labels = np.concatenate(labels, 0)\n",
    "    model.train()\n",
    "\n",
    "    return latents, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_latent_space(model, loss_items, experiment_name, test_loader, z_dims):\n",
    "\n",
    "    now = datetime.now()\n",
    "    pic_name = now.strftime(\"%Y%m%d%H%M%S%f\")\n",
    "\n",
    "    extent = 5\n",
    "\n",
    "    cmap = plt.cm.tab20\n",
    "    bounds = np.linspace(0,10,11)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    latents, labels = eval_on_test(model, test_loader)\n",
    "    if extent is not None: \n",
    "        ax.set_xlim(-extent, extent)\n",
    "        ax.set_ylim(-extent, extent)\n",
    "    scat = ax.scatter(latents[:, 0], latents[:,1], s=2, marker='o', cmap=cmap, c=labels)\n",
    "    cb = plt.colorbar(scat, spacing='proportional',ticks=bounds)\n",
    "\n",
    "    title = f\"Recon: {loss_items[0].item():2.3f}, KLD {loss_items[1].item():2.3f}\"\n",
    "    ax.set_title(title)\n",
    "\n",
    "    path1 = rf'latent_space_vis\\{experiment_name}'\n",
    "\n",
    "    if not os.path.exists(path1):\n",
    "        os.makedirs(path1)\n",
    "\n",
    "    fig.savefig(path1 + rf'\\{pic_name}.jpg')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return reconstruction error + KL divergence losses\n",
    "def vae_loss(recon_x, x, mu, log_var):\n",
    "    B, C, H, W = recon_x.shape\n",
    "    beta = 0.1 #legend says, that the bigger beta is, the higher the disentanglement\n",
    "    recons_loss = F.mse_loss(recon_x.view(B, -1), x.view(B, -1), reduction=\"mean\")\n",
    "    KLD = beta * -0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp()) # 1 + log(sigma**2) - mu**2 - sigma**2\n",
    "    return recons_loss, KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_image(image):\n",
    "    dtype = image.dtype\n",
    "    image = image.astype(float)\n",
    "    image = image - np.min(image)\n",
    "    image = image / np.max(image) * 255\n",
    "    image = image.astype(dtype)\n",
    "    return image\n",
    "\n",
    "def save_recon(x_recon, experiment_name):\n",
    "    image = x_recon[0].permute(1, 2, 0).detach().cpu().numpy()\n",
    "    now = datetime.now()\n",
    "    pic_name = now.strftime(\"%Y%m%d%H%M%S%f\")\n",
    "    path =  f\"latent_space_vis/{experiment_name}/recons\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    cv2.imwrite(os.path.join(path, f\"{pic_name}.jpg\"), norm_image(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_f, train_loader, test_loader, optimizer, scheduler, epoch, experiment_name, embedding_size):\n",
    "    np.set_printoptions(precision=2)\n",
    "    if embedding_size > 2: vis = False\n",
    "    else: vis = True\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    for batch_idx, (x, _) in enumerate(train_loader):\n",
    "        x = x.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x_recon, mu, log_var = model(x)\n",
    "        std2 = log_var.exp().sqrt().mean(0)*2\n",
    "        x_recon = x_recon[:, 0, None, :, :]\n",
    "\n",
    "        rec, KLD = loss_f(x_recon, x, mu, log_var)\n",
    "        loss = rec + KLD\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # print(scheduler.get_last_lr())\n",
    "\n",
    "        if batch_idx % 25 == 0:\n",
    "            if vis: \n",
    "                visualize_latent_space(model, (rec, KLD), experiment_name, test_loader)\n",
    "                \n",
    "            save_recon(x_recon, experiment_name)\n",
    "            print(\"Epoch {:3} Iteration {:3}: recon: {:8.4f}, kld: {:8.4f}, std2: {}\".format(epoch, batch_idx, rec.item(), KLD.item(), std2.detach().cpu().numpy()))\n",
    "\n",
    "    path =  \"models/{experiment_name}\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # save_model_to = f\"{path}/vae_{epoch}.pth\"\n",
    "    # torch.save(model.state_dict(), save_model_to)\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 8\n",
    "\n",
    "\n",
    "# build model\n",
    "vae = VAE(sample_x=example_data, hidden_dims=None, z_dim=embedding_size)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 Iteration   0: recon:   2.0797, kld:   0.0121, std2: [1.9  2.51 2.   2.04 2.23 2.03 2.38 1.89]\n",
      "Epoch   1 Iteration  25: recon:   0.8169, kld:   0.0758, std2: [0.75 0.89 1.14 1.23 0.96 1.14 1.02 1.57]\n",
      "Epoch   1 Iteration  50: recon:   0.8177, kld:   0.0734, std2: [0.89 0.84 1.12 1.14 1.15 1.02 1.06 1.41]\n",
      "Epoch   1 Iteration  75: recon:   0.7282, kld:   0.0798, std2: [0.9  0.86 1.23 1.05 0.88 0.97 0.82 1.18]\n",
      "Epoch   1 Iteration 100: recon:   0.6081, kld:   0.0904, std2: [0.72 0.81 0.85 1.02 1.03 0.77 0.86 1.59]\n",
      "Epoch   1 Iteration 125: recon:   0.5653, kld:   0.0851, std2: [0.76 0.78 1.06 0.82 1.04 0.75 0.71 1.25]\n",
      "Epoch   2 Iteration   0: recon:   0.5370, kld:   0.0951, std2: [0.67 0.77 0.86 0.78 1.08 0.62 0.61 1.3 ]\n",
      "Epoch   2 Iteration  25: recon:   0.5470, kld:   0.1075, std2: [0.66 0.85 0.95 0.79 1.07 0.8  0.73 1.02]\n",
      "Epoch   2 Iteration  50: recon:   0.4571, kld:   0.1025, std2: [0.69 0.7  0.91 0.69 0.96 0.6  0.62 1.  ]\n",
      "Epoch   2 Iteration  75: recon:   0.4100, kld:   0.1154, std2: [0.63 0.68 0.64 0.61 0.9  0.57 0.53 0.92]\n",
      "Epoch   2 Iteration 100: recon:   0.4409, kld:   0.1265, std2: [0.61 0.66 0.57 0.89 0.67 0.53 0.64 0.68]\n",
      "Epoch   2 Iteration 125: recon:   0.3633, kld:   0.1311, std2: [0.59 0.62 0.7  0.52 0.94 0.42 0.45 0.78]\n",
      "Epoch   3 Iteration   0: recon:   0.3660, kld:   0.1166, std2: [0.64 0.65 0.72 0.7  0.8  0.55 0.47 1.  ]\n",
      "Epoch   3 Iteration  25: recon:   0.3626, kld:   0.1266, std2: [0.64 0.7  0.63 0.43 0.7  0.52 0.47 0.79]\n",
      "Epoch   3 Iteration  50: recon:   0.3724, kld:   0.1207, std2: [0.75 0.68 0.7  0.64 1.03 0.45 0.58 0.85]\n",
      "Epoch   3 Iteration  75: recon:   0.3409, kld:   0.1289, std2: [0.58 0.68 0.63 0.56 0.68 0.55 0.47 0.89]\n",
      "Epoch   3 Iteration 100: recon:   0.3456, kld:   0.1266, std2: [0.59 0.67 0.58 0.48 0.6  0.49 0.41 0.77]\n",
      "Epoch   3 Iteration 125: recon:   0.3652, kld:   0.1362, std2: [0.63 0.69 0.72 0.64 0.7  0.45 0.51 0.67]\n",
      "Epoch   4 Iteration   0: recon:   0.3384, kld:   0.1212, std2: [0.56 0.67 0.71 0.56 0.68 0.64 0.45 0.94]\n",
      "Epoch   4 Iteration  25: recon:   0.3267, kld:   0.1264, std2: [0.6  0.65 0.64 0.5  0.69 0.45 0.47 0.81]\n",
      "Epoch   4 Iteration  50: recon:   0.3154, kld:   0.1287, std2: [0.53 0.6  0.7  0.49 0.72 0.51 0.46 0.72]\n",
      "Epoch   4 Iteration  75: recon:   0.3129, kld:   0.1321, std2: [0.57 0.64 0.62 0.52 0.75 0.56 0.44 0.85]\n",
      "Epoch   4 Iteration 100: recon:   0.3139, kld:   0.1263, std2: [0.57 0.68 0.66 0.51 0.65 0.45 0.46 0.8 ]\n",
      "Epoch   4 Iteration 125: recon:   0.3224, kld:   0.1314, std2: [0.51 0.76 0.56 0.52 0.69 0.42 0.4  0.78]\n",
      "Epoch   5 Iteration   0: recon:   0.3371, kld:   0.1182, std2: [0.7  0.93 0.79 0.61 0.97 0.74 0.52 0.95]\n",
      "Epoch   5 Iteration  25: recon:   0.2958, kld:   0.1280, std2: [0.62 0.69 0.65 0.51 0.7  0.49 0.47 0.75]\n",
      "Epoch   5 Iteration  50: recon:   0.2869, kld:   0.1385, std2: [0.61 0.66 0.62 0.38 0.53 0.39 0.37 0.66]\n",
      "Epoch   5 Iteration  75: recon:   0.3039, kld:   0.1315, std2: [0.53 0.8  0.66 0.49 0.75 0.49 0.34 0.82]\n",
      "Epoch   5 Iteration 100: recon:   0.3051, kld:   0.1322, std2: [0.51 0.7  0.56 0.55 0.68 0.45 0.45 0.86]\n",
      "Epoch   5 Iteration 125: recon:   0.2836, kld:   0.1329, std2: [0.6  0.65 0.6  0.44 0.64 0.44 0.37 0.72]\n",
      "Epoch   6 Iteration   0: recon:   0.2871, kld:   0.1380, std2: [0.46 0.65 0.54 0.42 0.63 0.49 0.32 0.74]\n",
      "Epoch   6 Iteration  25: recon:   0.3119, kld:   0.1237, std2: [0.73 0.77 0.75 0.57 1.03 0.48 0.53 0.95]\n",
      "Epoch   6 Iteration  50: recon:   0.2816, kld:   0.1327, std2: [0.61 0.69 0.55 0.52 0.58 0.5  0.43 0.71]\n",
      "Epoch   6 Iteration  75: recon:   0.2667, kld:   0.1286, std2: [0.53 0.67 0.61 0.48 0.73 0.42 0.41 0.73]\n",
      "Epoch   6 Iteration 100: recon:   0.2721, kld:   0.1419, std2: [0.64 0.53 0.56 0.42 0.61 0.35 0.44 0.71]\n",
      "Epoch   6 Iteration 125: recon:   0.2780, kld:   0.1316, std2: [0.6  0.72 0.57 0.44 0.77 0.45 0.37 0.76]\n",
      "Epoch   7 Iteration   0: recon:   0.2958, kld:   0.1382, std2: [0.59 0.66 0.58 0.46 0.64 0.45 0.34 0.75]\n",
      "Epoch   7 Iteration  25: recon:   0.3105, kld:   0.1270, std2: [0.56 0.64 0.65 0.52 0.61 0.5  0.42 0.97]\n",
      "Epoch   7 Iteration  50: recon:   0.2742, kld:   0.1365, std2: [0.48 0.71 0.62 0.45 0.68 0.35 0.31 0.75]\n",
      "Epoch   7 Iteration  75: recon:   0.2626, kld:   0.1330, std2: [0.59 0.64 0.58 0.42 0.65 0.43 0.37 0.76]\n",
      "Epoch   7 Iteration 100: recon:   0.2917, kld:   0.1326, std2: [0.55 0.59 0.66 0.45 0.65 0.45 0.42 0.83]\n",
      "Epoch   7 Iteration 125: recon:   0.2900, kld:   0.1363, std2: [0.5  0.57 0.64 0.55 0.73 0.4  0.37 0.8 ]\n",
      "Epoch   8 Iteration   0: recon:   0.2759, kld:   0.1314, std2: [0.64 0.64 0.62 0.48 0.65 0.48 0.39 0.82]\n",
      "Epoch   8 Iteration  25: recon:   0.2741, kld:   0.1345, std2: [0.59 0.69 0.62 0.44 0.65 0.41 0.38 0.8 ]\n",
      "Epoch   8 Iteration  50: recon:   0.2677, kld:   0.1239, std2: [0.69 0.89 0.79 0.45 0.72 0.46 0.39 0.83]\n",
      "Epoch   8 Iteration  75: recon:   0.2742, kld:   0.1307, std2: [0.63 0.78 0.64 0.43 0.69 0.42 0.4  0.71]\n",
      "Epoch   8 Iteration 100: recon:   0.2528, kld:   0.1342, std2: [0.64 0.65 0.63 0.39 0.6  0.41 0.38 0.8 ]\n",
      "Epoch   8 Iteration 125: recon:   0.2858, kld:   0.1296, std2: [0.59 0.67 0.64 0.53 0.76 0.4  0.41 0.67]\n",
      "Epoch   9 Iteration   0: recon:   0.2814, kld:   0.1452, std2: [0.72 0.73 0.55 0.42 0.53 0.4  0.33 0.84]\n",
      "Epoch   9 Iteration  25: recon:   0.2538, kld:   0.1399, std2: [0.56 0.65 0.51 0.41 0.6  0.39 0.35 0.78]\n",
      "Epoch   9 Iteration  50: recon:   0.2635, kld:   0.1402, std2: [0.52 0.64 0.6  0.4  0.62 0.37 0.34 0.64]\n",
      "Epoch   9 Iteration  75: recon:   0.2893, kld:   0.1305, std2: [0.72 0.77 0.71 0.38 0.68 0.34 0.41 0.84]\n",
      "Epoch   9 Iteration 100: recon:   0.2640, kld:   0.1404, std2: [0.53 0.72 0.53 0.4  0.59 0.38 0.38 0.73]\n",
      "Epoch   9 Iteration 125: recon:   0.2474, kld:   0.1315, std2: [0.59 0.71 0.59 0.45 0.65 0.4  0.35 0.78]\n",
      "Epoch  10 Iteration   0: recon:   0.2700, kld:   0.1334, std2: [0.65 0.73 0.62 0.4  0.69 0.46 0.3  0.74]\n",
      "Epoch  10 Iteration  25: recon:   0.2784, kld:   0.1357, std2: [0.62 0.75 0.62 0.4  0.71 0.39 0.34 0.77]\n",
      "Epoch  10 Iteration  50: recon:   0.2457, kld:   0.1341, std2: [0.61 0.69 0.61 0.41 0.61 0.4  0.38 0.83]\n",
      "Epoch  10 Iteration  75: recon:   0.2618, kld:   0.1352, std2: [0.66 0.64 0.56 0.45 0.59 0.42 0.36 0.83]\n",
      "Epoch  10 Iteration 100: recon:   0.2645, kld:   0.1414, std2: [0.68 0.73 0.54 0.42 0.51 0.37 0.42 0.87]\n",
      "Epoch  10 Iteration 125: recon:   0.2376, kld:   0.1297, std2: [0.63 0.69 0.6  0.42 0.65 0.37 0.34 0.79]\n",
      "Epoch  11 Iteration   0: recon:   0.2334, kld:   0.1418, std2: [0.58 0.67 0.54 0.39 0.59 0.36 0.33 0.74]\n",
      "Epoch  11 Iteration  25: recon:   0.2492, kld:   0.1425, std2: [0.48 0.72 0.54 0.4  0.54 0.36 0.33 0.76]\n",
      "Epoch  11 Iteration  50: recon:   0.2487, kld:   0.1387, std2: [0.57 0.74 0.59 0.39 0.62 0.43 0.33 0.76]\n",
      "Epoch  11 Iteration  75: recon:   0.2265, kld:   0.1417, std2: [0.58 0.65 0.52 0.37 0.59 0.35 0.33 0.73]\n",
      "Epoch  11 Iteration 100: recon:   0.2428, kld:   0.1361, std2: [0.52 0.69 0.61 0.39 0.66 0.38 0.33 0.76]\n",
      "Epoch  11 Iteration 125: recon:   0.2626, kld:   0.1444, std2: [0.52 0.66 0.58 0.41 0.51 0.32 0.31 0.73]\n",
      "Epoch  12 Iteration   0: recon:   0.2305, kld:   0.1363, std2: [0.56 0.66 0.57 0.41 0.64 0.37 0.34 0.8 ]\n",
      "Epoch  12 Iteration  25: recon:   0.2496, kld:   0.1342, std2: [0.63 0.72 0.58 0.45 0.65 0.38 0.32 0.74]\n",
      "Epoch  12 Iteration  50: recon:   0.2723, kld:   0.1455, std2: [0.52 0.6  0.5  0.42 0.58 0.36 0.37 0.79]\n",
      "Epoch  12 Iteration  75: recon:   0.2366, kld:   0.1385, std2: [0.63 0.63 0.55 0.4  0.7  0.35 0.34 0.8 ]\n",
      "Epoch  12 Iteration 100: recon:   0.2418, kld:   0.1419, std2: [0.59 0.7  0.56 0.37 0.57 0.35 0.32 0.73]\n",
      "Epoch  12 Iteration 125: recon:   0.2497, kld:   0.1354, std2: [0.59 0.7  0.61 0.35 0.53 0.43 0.32 0.81]\n",
      "Epoch  13 Iteration   0: recon:   0.2515, kld:   0.1422, std2: [0.61 0.62 0.55 0.43 0.58 0.32 0.37 0.75]\n",
      "Epoch  13 Iteration  25: recon:   0.2354, kld:   0.1383, std2: [0.6  0.73 0.53 0.37 0.62 0.38 0.34 0.76]\n",
      "Epoch  13 Iteration  50: recon:   0.2146, kld:   0.1452, std2: [0.59 0.71 0.57 0.32 0.56 0.33 0.28 0.76]\n",
      "Epoch  13 Iteration  75: recon:   0.2490, kld:   0.1363, std2: [0.54 0.7  0.51 0.4  0.59 0.39 0.34 0.92]\n",
      "Epoch  13 Iteration 100: recon:   0.2245, kld:   0.1442, std2: [0.6  0.67 0.53 0.37 0.62 0.36 0.3  0.68]\n",
      "Epoch  13 Iteration 125: recon:   0.2298, kld:   0.1362, std2: [0.62 0.72 0.51 0.38 0.64 0.37 0.35 0.88]\n",
      "Epoch  14 Iteration   0: recon:   0.2223, kld:   0.1441, std2: [0.59 0.69 0.45 0.37 0.59 0.37 0.31 0.9 ]\n",
      "Epoch  14 Iteration  25: recon:   0.2444, kld:   0.1426, std2: [0.59 0.73 0.57 0.4  0.51 0.36 0.34 0.8 ]\n",
      "Epoch  14 Iteration  50: recon:   0.2098, kld:   0.1368, std2: [0.57 0.71 0.52 0.37 0.65 0.38 0.32 0.8 ]\n",
      "Epoch  14 Iteration  75: recon:   0.2024, kld:   0.1550, std2: [0.48 0.66 0.41 0.29 0.61 0.28 0.29 0.71]\n",
      "Epoch  14 Iteration 100: recon:   0.2436, kld:   0.1327, std2: [0.63 0.85 0.68 0.4  0.61 0.42 0.31 0.97]\n",
      "Epoch  14 Iteration 125: recon:   0.2213, kld:   0.1457, std2: [0.56 0.68 0.52 0.35 0.54 0.32 0.3  0.76]\n",
      "Epoch  15 Iteration   0: recon:   0.2067, kld:   0.1405, std2: [0.6  0.7  0.55 0.35 0.61 0.36 0.3  0.78]\n",
      "Epoch  15 Iteration  25: recon:   0.2241, kld:   0.1383, std2: [0.52 0.69 0.56 0.48 0.61 0.34 0.32 0.72]\n",
      "Epoch  15 Iteration  50: recon:   0.2170, kld:   0.1423, std2: [0.56 0.73 0.54 0.35 0.62 0.36 0.31 0.83]\n",
      "Epoch  15 Iteration  75: recon:   0.2167, kld:   0.1427, std2: [0.55 0.7  0.54 0.31 0.58 0.32 0.3  0.73]\n",
      "Epoch  15 Iteration 100: recon:   0.2378, kld:   0.1385, std2: [0.56 0.77 0.53 0.33 0.57 0.36 0.3  0.8 ]\n",
      "Epoch  15 Iteration 125: recon:   0.2344, kld:   0.1409, std2: [0.54 0.68 0.55 0.4  0.55 0.39 0.32 0.8 ]\n",
      "Epoch  16 Iteration   0: recon:   0.2100, kld:   0.1471, std2: [0.55 0.7  0.53 0.36 0.6  0.32 0.29 0.75]\n",
      "Epoch  16 Iteration  25: recon:   0.2088, kld:   0.1459, std2: [0.58 0.71 0.49 0.31 0.54 0.35 0.29 0.68]\n",
      "Epoch  16 Iteration  50: recon:   0.2483, kld:   0.1348, std2: [0.62 0.81 0.52 0.44 0.63 0.34 0.3  0.91]\n",
      "Epoch  16 Iteration  75: recon:   0.2194, kld:   0.1420, std2: [0.63 0.73 0.48 0.34 0.59 0.33 0.27 0.75]\n",
      "Epoch  16 Iteration 100: recon:   0.2211, kld:   0.1442, std2: [0.56 0.72 0.56 0.33 0.55 0.35 0.29 0.82]\n",
      "Epoch  16 Iteration 125: recon:   0.2166, kld:   0.1477, std2: [0.53 0.72 0.45 0.36 0.61 0.31 0.28 0.83]\n",
      "Epoch  17 Iteration   0: recon:   0.2276, kld:   0.1490, std2: [0.53 0.75 0.48 0.35 0.55 0.32 0.28 0.76]\n",
      "Epoch  17 Iteration  25: recon:   0.2038, kld:   0.1423, std2: [0.57 0.73 0.51 0.37 0.6  0.33 0.29 0.86]\n",
      "Epoch  17 Iteration  50: recon:   0.2270, kld:   0.1423, std2: [0.59 0.72 0.51 0.37 0.61 0.3  0.3  0.83]\n",
      "Epoch  17 Iteration  75: recon:   0.2355, kld:   0.1500, std2: [0.52 0.75 0.58 0.32 0.49 0.33 0.35 0.82]\n",
      "Epoch  17 Iteration 100: recon:   0.2015, kld:   0.1444, std2: [0.57 0.73 0.54 0.34 0.57 0.31 0.29 0.76]\n",
      "Epoch  17 Iteration 125: recon:   0.2137, kld:   0.1474, std2: [0.49 0.7  0.52 0.32 0.53 0.33 0.3  0.72]\n",
      "Epoch  18 Iteration   0: recon:   0.2054, kld:   0.1471, std2: [0.53 0.81 0.49 0.35 0.57 0.32 0.27 0.77]\n",
      "Epoch  18 Iteration  25: recon:   0.2111, kld:   0.1498, std2: [0.53 0.71 0.46 0.36 0.56 0.31 0.28 0.83]\n",
      "Epoch  18 Iteration  50: recon:   0.1928, kld:   0.1368, std2: [0.56 0.78 0.51 0.35 0.64 0.32 0.29 0.9 ]\n",
      "Epoch  18 Iteration  75: recon:   0.2103, kld:   0.1470, std2: [0.57 0.71 0.48 0.31 0.54 0.32 0.27 0.83]\n",
      "Epoch  18 Iteration 100: recon:   0.2487, kld:   0.1454, std2: [0.53 0.76 0.57 0.36 0.62 0.29 0.28 0.8 ]\n",
      "Epoch  18 Iteration 125: recon:   0.1850, kld:   0.1444, std2: [0.52 0.71 0.49 0.33 0.53 0.34 0.28 0.81]\n",
      "Epoch  19 Iteration   0: recon:   0.2217, kld:   0.1450, std2: [0.57 0.71 0.52 0.37 0.6  0.34 0.28 0.84]\n",
      "Epoch  19 Iteration  25: recon:   0.2102, kld:   0.1487, std2: [0.49 0.67 0.54 0.33 0.57 0.32 0.25 0.71]\n",
      "Epoch  19 Iteration  50: recon:   0.2013, kld:   0.1446, std2: [0.52 0.71 0.49 0.33 0.57 0.33 0.25 0.8 ]\n",
      "Epoch  19 Iteration  75: recon:   0.2227, kld:   0.1472, std2: [0.53 0.7  0.48 0.35 0.53 0.31 0.29 0.83]\n",
      "Epoch  19 Iteration 100: recon:   0.2025, kld:   0.1457, std2: [0.6  0.75 0.54 0.36 0.54 0.31 0.25 0.88]\n",
      "Epoch  19 Iteration 125: recon:   0.2237, kld:   0.1446, std2: [0.58 0.79 0.56 0.37 0.56 0.31 0.28 0.85]\n",
      "Epoch  20 Iteration   0: recon:   0.2081, kld:   0.1474, std2: [0.55 0.73 0.51 0.36 0.57 0.32 0.28 0.8 ]\n",
      "Epoch  20 Iteration  25: recon:   0.2036, kld:   0.1407, std2: [0.57 0.78 0.52 0.36 0.63 0.32 0.29 0.86]\n",
      "Epoch  20 Iteration  50: recon:   0.2099, kld:   0.1406, std2: [0.61 0.78 0.53 0.35 0.64 0.31 0.27 0.9 ]\n",
      "Epoch  20 Iteration  75: recon:   0.1919, kld:   0.1429, std2: [0.59 0.72 0.47 0.36 0.58 0.33 0.27 0.9 ]\n",
      "Epoch  20 Iteration 100: recon:   0.2047, kld:   0.1484, std2: [0.55 0.72 0.49 0.35 0.55 0.28 0.27 0.77]\n",
      "Epoch  20 Iteration 125: recon:   0.1932, kld:   0.1494, std2: [0.54 0.66 0.45 0.37 0.54 0.28 0.26 0.75]\n"
     ]
    }
   ],
   "source": [
    "# # remember: acceptable recon loss is 0.45\n",
    "num_epochs = 20\n",
    "\n",
    "experiment_name = f\"10_syntensor_only\"\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(vae, vae_loss, data['train'], data['test'], optimizer, scheduler, epoch, experiment_name, embedding_size=embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(vae, \"models/vae_promaton.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: [0.63 0.5  0.46 0.24 0.23 0.34 0.47 0.6 ] \n",
      "std2: [2.32 2.43 2.03 1.28 1.22 1.81 2.29 3.05] \n",
      " 526\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from IPython.display import clear_output\n",
    "import multiprocessing as mp\n",
    "\n",
    "# this is needed to normalize sound; if you will change z-dim size, you should recalcualte\n",
    "# these things. From this example you Ґcan see, that for techno music we've got a huge\n",
    "# mean for bass (1 position) and low mean value for high freqs\n",
    "# mean =  [510.15845655661803, 135.35665321114695, 102.851305103906, 63.160291749979983]\n",
    "# std1 =  [700.373306840422, 135.12631741685448, 102.5477751543778, 63.582527648859525]\n",
    "\n",
    "std = [0.00056372, 0.00181005, 0.00298502, 0.00497356, 0.00476172,\n",
    "       0.00467349, 0.00724976, 0.02696994]\n",
    "mean = [-1314.773    ,  -256.68332  ,  -139.03033  ,   -91.24173  ,\n",
    "        -111.323074 ,  -109.316895 ,   -63.288567 ,   -14.2479315]\n",
    "mean, std = torch.Tensor(mean).to(\"cuda\"), torch.Tensor(std).to(\"cuda\")\n",
    "\n",
    "query = \"default\"\n",
    "vae.eval()\n",
    "vae.cuda()\n",
    "\n",
    "steps = 0 #current transformation matrix\n",
    "mat2 = torch.eye(embedding_size)\n",
    "values = []\n",
    "\n",
    "stream = RealTimeAudioStream(query=query, z_dim=embedding_size)\n",
    "stream.start_audio_process()\n",
    "response = None\n",
    "with torch.no_grad():\n",
    "    while True:\n",
    "        response = stream.step_process()\n",
    "        rms, zcr, fft = response\n",
    "        \n",
    "        # here we are perfoming a basis change.\n",
    "        # basis 1 is the last one, we've been to\n",
    "        # then we pick random basis 2 and slowly\n",
    "        # traversing towards it\n",
    "        if steps==0:\n",
    "            steps = random.randint(2, 200)\n",
    "            mat1 = mat2.clone()\n",
    "            mat2 = random_rotation_matrix(embedding_size)\n",
    "\n",
    "            rots = interpolate_transforms(mat2, mat1, steps)\n",
    "        \n",
    "        steps -= 1\n",
    "        r_m = rots[steps].to(\"cuda\")\n",
    "\n",
    "        # rms = ((rms - 0.15) * 12) # 0.3\n",
    "        # zcr = ((zcr - 0.07) * 24)# 0.14\n",
    "        # print(angle_r, rms, zcr, end=\"\\r\")\n",
    "        # z = (torch.tensor([rms, zcr]) @ r_m).unsqueeze(0).to(\"cuda\") \n",
    "        ######\n",
    "        z = fft[0, :, 0].float()\n",
    "        z += (mean)\n",
    "        z *= (std)\n",
    "        # z = z @ r_m\n",
    "        ######\n",
    "        # print(fft)\n",
    "        values.append(z.cpu().numpy())\n",
    "        print(\"mean:\", np.mean(values, 0), \"\\nstd2:\", np.std(values, 0) * 2, \"\\n\", len(values))\n",
    "\n",
    "        sample = vae.decoder(z.cuda())\n",
    "        sample = (sample + 1) / 2 \n",
    "        image = sample[0].permute(1, 2, 0).detach().cpu().numpy()\n",
    "        image = cv2.resize(image, (1024, 512))\n",
    "\n",
    "\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        cv2.imshow(\"generation\", image)\n",
    "\n",
    "        k = cv2.waitKey(33)\n",
    "        if k==27:    # Esc key to stop\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#audio_stream.stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51353484, -0.34026122, -0.2533055 , -0.3103051 , -0.43936414,\n",
       "       -0.47857332, -0.42765737, -0.28083706], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.mean(values, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.1778342e-07, 3.2762962e-06, 8.9103723e-06, 2.4736308e-05,\n",
       "       2.2673956e-05, 2.1841470e-05, 5.2558982e-05, 7.2737777e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / np.var(values, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.58372385e-14, 3.59560802e-13, 1.56496772e-12, 4.87622144e-12,\n",
       "       5.33377916e-12, 5.77753957e-12, 1.55590976e-11, 1.82130491e-10])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square([2.1409633e-07, 5.9963389e-07, 1.2509867e-06, 2.2082168e-06,\n",
    "       2.3094976e-06, 2.4036513e-06, 3.9445022e-06, 1.3495573e-05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00056372, 0.00181005, 0.00298502, 0.00497356, 0.00476172,\n",
       "       0.00467349, 0.00724976, 0.02696994])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt([3.1778342e-07, 3.2762962e-06, 8.9103723e-06, 2.4736308e-05,\n",
    "       2.2673956e-05, 2.1841470e-05, 5.2558982e-05, 7.2737777e-04])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sound_vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
