{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import utils, datasets\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils.audio_utils import RealTimeAudioStream\n",
    "from utils.vaes import *    \n",
    "from utils.data_utils import calculate_mean_std, split_train_val_test\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import math\n",
    "\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# this ensures that the current MacOS version is at least 12.3+\n",
    "print(torch.backends.mps.is_available())\n",
    "# this ensures that the current current PyTorch installation was built with MPS activated.\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream your audio output and check what it visualizes\n",
    "\n",
    "# короче блять работает хуйня єта ебаная (PyAudio) только с микрофонами по-нормальному\n",
    "# а чтоб стримить аутпут системьі, то конечно лучше юзать пєкєдж soundcard\n",
    "# но там немного другой принцип работьі и єто охуеть можно\n",
    "# так что по ходу надо попробовать єтое: https://github.com/intxcc/pyaudio_portaudio/tree/master\n",
    "# audio_stream = RealTimeAudioStream()\n",
    "# audio_stream.stream(rms=True, zcr=True, fft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rotation_matrix(dim):\n",
    "    # Generate a random orthogonal matrix\n",
    "    x = torch.randn(dim, dim).requires_grad_(False)\n",
    "    q, _ = torch.linalg.qr(x)\n",
    "    \n",
    "    # Apply the SVD decomposition to obtain the rotation matrix\n",
    "    u, _, v = torch.linalg.svd(q)\n",
    "    rotation_matrix = u @ v.mT\n",
    "    \n",
    "    return rotation_matrix\n",
    "\n",
    "def interpolate_transforms(matrix1, matrix2, steps):\n",
    "    # Interpolate between two rotation matrices\n",
    "    transforms = []\n",
    "    for t in range(steps + 1):\n",
    "        weight = t / steps\n",
    "        interpolated_matrix = torch.lerp(matrix1, matrix2, weight).requires_grad_(False)\n",
    "        transforms.append(interpolated_matrix)\n",
    "    return transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom dataset\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "WIDTH = 256\n",
    "HEIGHT = 128\n",
    "\n",
    "dataset_dir = r\"data/prepared\"\n",
    "\n",
    "# calculate dataset mean and std\n",
    "raw_transforms = T.Compose([\n",
    "    T.Resize((HEIGHT, WIDTH)), \n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "raw_data = datasets.ImageFolder(root = dataset_dir, transform = raw_transforms)\n",
    "\n",
    "# DATA_MEAN, DATA_STD = calculate_mean_std(raw_data)\n",
    "DATA_MEAN = [0.9358, 0.9358, 0.9358]\n",
    "DATA_STD  = [0.2308, 0.2308, 0.2308]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/Documents/sound_vae/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/dmitry/Documents/sound_vae/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/dmitry/Documents/sound_vae/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/dmitry/Documents/sound_vae/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 128, 256])\n",
      "tensor(0.)\n",
      "tensor(0.9999)\n"
     ]
    }
   ],
   "source": [
    "data_transforms = T.Compose([\n",
    "    T.Resize((HEIGHT, WIDTH)), \n",
    "    T.ToTensor(),\n",
    "    T.Grayscale(),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root = dataset_dir, transform = data_transforms)\n",
    "\n",
    "# split into Train, Val and Test\n",
    "data = split_train_val_test(dataset, val=0.0, test=0.1, batch_size=batch_size)\n",
    "\n",
    "examples = enumerate(data['train'])\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(example_data.shape)\n",
    "print(example_data.min())\n",
    "print(example_data.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_test(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        latents = []\n",
    "        labels = []\n",
    "        for x, y in test_loader:\n",
    "            mu, log_var = model.encoder(x.mps())\n",
    "            z = model.sampling(mu, log_var).cpu().numpy()\n",
    "\n",
    "            latents.append(z)\n",
    "            labels.append(y)\n",
    "\n",
    "    latents = np.concatenate(latents, 0)\n",
    "    labels = np.concatenate(labels, 0)\n",
    "    model.train()\n",
    "\n",
    "    return latents, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_latent_space(model, loss_items, experiment_name, test_loader, z_dims):\n",
    "\n",
    "    now = datetime.now()\n",
    "    pic_name = now.strftime(\"%Y%m%d%H%M%S%f\")\n",
    "\n",
    "    extent = 5\n",
    "\n",
    "    cmap = plt.cm.tab20\n",
    "    bounds = np.linspace(0,10,11)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    latents, labels = eval_on_test(model, test_loader)\n",
    "    if extent is not None: \n",
    "        ax.set_xlim(-extent, extent)\n",
    "        ax.set_ylim(-extent, extent)\n",
    "    scat = ax.scatter(latents[:, 0], latents[:,1], s=2, marker='o', cmap=cmap, c=labels)\n",
    "    cb = plt.colorbar(scat, spacing='proportional',ticks=bounds)\n",
    "\n",
    "    title = f\"Recon: {loss_items[0].item():2.3f}, KLD {loss_items[1].item():2.3f}\"\n",
    "    ax.set_title(title)\n",
    "\n",
    "    path1 = rf'latent_space_vis\\{experiment_name}'\n",
    "\n",
    "    if not os.path.exists(path1):\n",
    "        os.makedirs(path1)\n",
    "\n",
    "    fig.savefig(path1 + rf'\\{pic_name}.jpg')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_image(image):\n",
    "    image = (image + 1) / 2\n",
    "    image = image * 255\n",
    "    return image\n",
    "\n",
    "def save_recon(x_recon, experiment_name):\n",
    "    image = x_recon[0].permute(1, 2, 0).detach().cpu().numpy()\n",
    "    now = datetime.now()\n",
    "    pic_name = now.strftime(\"%Y%m%d%H%M%S%f\")\n",
    "    path =  f\"latent_space_vis/{experiment_name}/recons\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    cv2.imwrite(os.path.join(path, f\"{pic_name}.jpg\"), norm_image(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return reconstruction error + KL divergence losses\n",
    "def vae_loss(recon_x, x, mu, log_var):\n",
    "    B, C, H, W = recon_x.shape\n",
    "    beta = 0.04 #legend says, that the bigger beta is, the higher the disentanglement\n",
    "    recons_loss = F.mse_loss(recon_x.view(B, -1), x.view(B, -1), reduction=\"mean\")\n",
    "    KLD = beta * -0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp()) # 1 + log(sigma**2) - mu**2 - sigma**2\n",
    "    return recons_loss, KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, loss_f, train_loader, optimizer, scheduler, epoch, experiment_name, device):\n",
    "    mean_rec = []\n",
    "    mean_kld = []\n",
    "    aggregated_z = []\n",
    "    for batch_idx, (x, _) in enumerate(train_loader):\n",
    "        x = x.to(device)\n",
    "        x = (x * 2) - 1\n",
    "        optimizer.zero_grad()\n",
    "        x_recon, mu, log_var = model(x)\n",
    "\n",
    "        rec, KLD = loss_f(x_recon, x, mu, log_var)\n",
    "        loss = rec + KLD\n",
    "        \n",
    "        mean_rec.append(rec)\n",
    "        mean_kld.append(KLD)\n",
    "\n",
    "        z = model.sampling(mu, log_var)\n",
    "        aggregated_z.append(z.detach().cpu().numpy())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # print(scheduler.get_last_lr())\n",
    "\n",
    "        if batch_idx % 100 == 0:                \n",
    "            save_recon(x_recon, experiment_name)\n",
    "            mean_rec = torch.as_tensor(mean_rec).mean().item()\n",
    "            mean_kld = torch.as_tensor(mean_kld).mean().item()\n",
    "            z_std = np.std(np.array(aggregated_z).reshape(-1, 8), 0)\n",
    "            print(\"Epoch {:3} Iteration {:3}: recon: {:8.4f}, kld: {:8.4f}\".format(\n",
    "                epoch, batch_idx, mean_rec, mean_kld)\n",
    "            )\n",
    "            print(f\"Z std: {z_std}\")\n",
    "            print(f\"Z mean: {np.mean(np.array(aggregated_z).reshape(-1, 8), 0)}\")\n",
    "            mean_rec = []\n",
    "            mean_kld = []\n",
    "            aggregated_z = []\n",
    "            # print(f\"mean: {mean.detach().cpu().numpy()}\")\n",
    "\n",
    "    # save_model_to = f\"{path}/vae_{epoch}.pth\"\n",
    "    # torch.save(model.state_dict(), save_model_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 8\n",
    "\n",
    "\n",
    "# build model\n",
    "# vae = VAE(shape=(HEIGHT, WIDTH), z_dim=embedding_size)\n",
    "# vae = torch.load(\"models/vae_promaton.pth\")\n",
    "optimizer = optim.Adam(vae.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/Documents/sound_vae/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/dmitry/Documents/sound_vae/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/dmitry/Documents/sound_vae/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/dmitry/Documents/sound_vae/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 Iteration   0: recon:   0.0300, kld:   0.0508\n",
      "Z std: [0.81 0.71 0.96 0.93 0.82 1.16 1.08 0.87]\n",
      "Z mean: [ 0.07 -0.35 -0.07  0.26  0.29 -0.22 -0.32 -0.21]\n",
      "Epoch   1 Iteration 100: recon:   0.0402, kld:   0.0496\n",
      "Z std: [1.   1.07 0.99 1.03 1.05 1.04 1.07 1.03]\n",
      "Z mean: [ 0.01 -0.03 -0.04 -0.03 -0.07  0.03  0.09  0.01]\n",
      "Epoch   1 Iteration 200: recon:   0.0369, kld:   0.0500\n",
      "Z std: [1.01 1.04 0.94 1.04 1.   1.04 1.04 1.01]\n",
      "Z mean: [ 0.   -0.04  0.   -0.02 -0.07 -0.02  0.03 -0.05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/Documents/sound_vae/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/dmitry/Documents/sound_vae/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/dmitry/Documents/sound_vae/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/dmitry/Documents/sound_vae/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   2 Iteration   0: recon:   0.0384, kld:   0.0496\n",
      "Z std: [0.74 0.94 0.84 0.96 1.04 1.19 1.01 1.06]\n",
      "Z mean: [ 0.25  0.29  0.18 -0.18 -0.25 -0.09 -0.11  0.24]\n",
      "Epoch   2 Iteration 100: recon:   0.0383, kld:   0.0490\n",
      "Z std: [0.99 1.05 0.95 1.03 1.02 1.03 1.05 1.01]\n",
      "Z mean: [ 0.01 -0.04 -0.02  0.01 -0.06 -0.01  0.04 -0.02]\n",
      "Epoch   2 Iteration 200: recon:   0.0375, kld:   0.0490\n",
      "Z std: [0.99 1.06 0.95 1.03 1.01 1.05 1.05 0.98]\n",
      "Z mean: [ 0.03 -0.   -0.01 -0.02 -0.01  0.    0.03 -0.01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/Documents/sound_vae/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/dmitry/Documents/sound_vae/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/dmitry/Documents/sound_vae/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/dmitry/Documents/sound_vae/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   3 Iteration   0: recon:   0.0393, kld:   0.0489\n",
      "Z std: [0.92 1.03 1.02 1.12 1.03 0.99 1.04 0.89]\n",
      "Z mean: [ 0.02 -0.16 -0.33 -0.1  -0.1  -0.02  0.24 -0.04]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x136ec28b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dmitry/Documents/sound_vae/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/dmitry/Documents/sound_vae/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1442, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/connection.py\", line 936, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[198], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m vae\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, num_epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> 14\u001b[0m     train_step(vae, vae_loss, data[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m], optimizer, scheduler, epoch, experiment_name, device\u001b[39m=\u001b[39;49mdevice)\n",
      "Cell \u001b[0;32mIn[192], line 6\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, loss_f, train_loader, optimizer, scheduler, epoch, experiment_name, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m aggregated_z \u001b[39m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (x, _) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m----> 6\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m      7\u001b[0m     x \u001b[39m=\u001b[39m (x \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      8\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "# # remember: acceptable recon loss is 0.45\n",
    "num_epochs = 30\n",
    "\n",
    "experiment_name = f\"10_syntensor_only\"\n",
    "vis = False\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "vae.train()\n",
    "vae.to(device)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_step(vae, vae_loss, data['train'], optimizer, scheduler, epoch, experiment_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(vae, \"models/vae_promaton.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[199], line 79\u001b[0m\n\u001b[1;32m     75\u001b[0m clear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     77\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mgeneration\u001b[39m\u001b[39m\"\u001b[39m, image)\n\u001b[0;32m---> 79\u001b[0m k \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m33\u001b[39;49m)\n\u001b[1;32m     80\u001b[0m \u001b[39mif\u001b[39;00m k\u001b[39m==\u001b[39m\u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):    \u001b[39m# q key to stop\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from IPython.display import clear_output\n",
    "import multiprocessing as mp\n",
    "\n",
    "# this is needed to normalize sound; if you will change z-dim size, you should recalcualte\n",
    "# these things. From this example you can see, that for techno music we've got a huge\n",
    "# mean for bass (1 position) and low mean value for high freqs\n",
    "# mean =  [510.15845655661803, 135.35665321114695, 102.851305103906, 63.160291749979983]\n",
    "# std1 =  [700.373306840422, 135.12631741685448, 102.5477751543778, 63.582527648859525]\n",
    "\n",
    "std = [0.00056372, 0.00181005, 0.00298502, 0.00497356, 0.00476172,\n",
    "       0.00467349, 0.00724976, 0.02696994]\n",
    "mean = [-1314.773    ,  -256.68332  ,  -139.03033  ,   -91.24173  ,\n",
    "        -111.323074 ,  -109.316895 ,   -63.288567 ,   -14.2479315]\n",
    "mean, std = torch.Tensor(mean).to(\"mps\"), torch.Tensor(std).to(\"mps\")\n",
    "\n",
    "query = \"Black\"\n",
    "# vae = torch.load(\"models/vae_promaton.pth\")\n",
    "vae.eval()\n",
    "vae.to(\"mps\")\n",
    "\n",
    "steps = 0 #current transformation matrix\n",
    "mat2 = torch.eye(embedding_size)\n",
    "sliding_window = torch.ones([40, embedding_size]).to(\"mps\")\n",
    "\n",
    "stream = RealTimeAudioStream(query=query, z_dim=embedding_size)\n",
    "stream.start_audio_process()\n",
    "response = None\n",
    "ind = 0\n",
    "with torch.no_grad():\n",
    "    while True:\n",
    "        response = stream.step_process()\n",
    "        rms, zcr, fft = response\n",
    "        fft = fft.to(torch.float32).to('mps')\n",
    "        \n",
    "        # here we are perfoming a basis change.\n",
    "        # basis 1 is the last one, we've been to\n",
    "        # then we pick random basis 2 and slowly\n",
    "        # traversing towards it\n",
    "        if steps==0:\n",
    "            steps = random.randint(2, 200)\n",
    "            mat1 = mat2.clone()\n",
    "            mat2 = random_rotation_matrix(embedding_size)\n",
    "\n",
    "            rots = interpolate_transforms(mat2, mat1, steps)\n",
    "        \n",
    "        steps -= 1\n",
    "        r_m = rots[steps].to(\"mps\")\n",
    "\n",
    "        # rms = ((rms - 0.15) * 12) # 0.3\n",
    "        # zcr = ((zcr - 0.07) * 24)# 0.14\n",
    "        # print(angle_r, rms, zcr, end=\"\\r\")\n",
    "        # z = (torch.tensor([rms, zcr]) @ r_m).unsqueeze(0).to(\"mps\") \n",
    "        ######\n",
    "        z = fft[0, :, 0].float()\n",
    "        sliding_window[ind % 40] = z\n",
    "        ind += 1\n",
    "\n",
    "        z -= torch.mean(sliding_window, 0)\n",
    "        z /= torch.std(sliding_window, 0) + 0.1\n",
    "        z *= 1.5\n",
    "        print(z)\n",
    "\n",
    "        # z = z @ r_m\n",
    "        ######\n",
    "        # print(fft)\n",
    "\n",
    "        sample = vae.decoder(z.to(\"mps\"))\n",
    "        image = sample[0].permute(1, 2, 0).detach().cpu().numpy()\n",
    "        image = (image + 1) / 2 \n",
    "        image = (image * 255).astype(np.uint8)\n",
    "        image = cv2.resize(image, (1024, 512))\n",
    "\n",
    "\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        cv2.imshow(\"generation\", image)\n",
    "\n",
    "        k = cv2.waitKey(33)\n",
    "        if k==ord('q'):    # q key to stop\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "for i in range(2):\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#audio_stream.stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51353484, -0.34026122, -0.2533055 , -0.3103051 , -0.43936414,\n",
       "       -0.47857332, -0.42765737, -0.28083706], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.mean(values, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.1778342e-07, 3.2762962e-06, 8.9103723e-06, 2.4736308e-05,\n",
       "       2.2673956e-05, 2.1841470e-05, 5.2558982e-05, 7.2737777e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / np.var(values, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.58372385e-14, 3.59560802e-13, 1.56496772e-12, 4.87622144e-12,\n",
       "       5.33377916e-12, 5.77753957e-12, 1.55590976e-11, 1.82130491e-10])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square([2.1409633e-07, 5.9963389e-07, 1.2509867e-06, 2.2082168e-06,\n",
    "       2.3094976e-06, 2.4036513e-06, 3.9445022e-06, 1.3495573e-05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00056372, 0.00181005, 0.00298502, 0.00497356, 0.00476172,\n",
       "       0.00467349, 0.00724976, 0.02696994])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt([3.1778342e-07, 3.2762962e-06, 8.9103723e-06, 2.4736308e-05,\n",
    "       2.2673956e-05, 2.1841470e-05, 5.2558982e-05, 7.2737777e-04])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 128, 64, 32, 16]\n",
      "[(8, 16), (16, 32), (32, 64), (64, 128), (128, 256)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected state_dict to be dict-like, got <class 'utils.vaes.VAE'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_pth \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mmodels/vae_promaton.pth\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m vae \u001b[39m=\u001b[39m VAE(sample_x\u001b[39m=\u001b[39mexample_data, hidden_dims\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, z_dim\u001b[39m=\u001b[39membedding_size)\n\u001b[0;32m----> 3\u001b[0m vae\u001b[39m.\u001b[39;49mload_state_dict(model_pth)\n",
      "File \u001b[0;32m~/Documents/sound_vae/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1994\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1971\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Copies parameters and buffers from :attr:`state_dict` into\u001b[39;00m\n\u001b[1;32m   1972\u001b[0m \u001b[39mthis module and its descendants. If :attr:`strict` is ``True``, then\u001b[39;00m\n\u001b[1;32m   1973\u001b[0m \u001b[39mthe keys of :attr:`state_dict` must exactly match the keys returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[39m    ``RuntimeError``.\u001b[39;00m\n\u001b[1;32m   1992\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1993\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(state_dict, Mapping):\n\u001b[0;32m-> 1994\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected state_dict to be dict-like, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(state_dict)))\n\u001b[1;32m   1996\u001b[0m missing_keys: List[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m []\n\u001b[1;32m   1997\u001b[0m unexpected_keys: List[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected state_dict to be dict-like, got <class 'utils.vaes.VAE'>."
     ]
    }
   ],
   "source": [
    "model_pth = torch.load(\"models/vae_promaton.pth\")\n",
    "vae = VAE(sample_x=example_data, hidden_dims=None, z_dim=embedding_size)\n",
    "vae.load_state_dict(model_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Mapping\n",
    "\n",
    "\n",
    "isinstance(model_pth, Mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder_layers): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (fc_mu): Linear(in_features=8192, out_features=8, bias=True)\n",
       "  (fc_var): Linear(in_features=8192, out_features=8, bias=True)\n",
       "  (decoder_input): Linear(in_features=8, out_features=32768, bias=True)\n",
       "  (decoder_layers): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Upsampler(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Upsampler(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Upsampler(\n",
       "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Upsampler(\n",
       "        (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (final_layer): Sequential(\n",
       "    (0): Upsampler(\n",
       "      (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Upsampler(\n",
       "      (conv): Conv2d(16, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (4): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sound_vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
